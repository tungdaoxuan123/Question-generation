# -*- coding: utf-8 -*-
"""Generate quetion.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GtWGr467rq0zOtknixsT9pzhggwjoNAu
"""
from pipelines import pipeline
# Commented out IPython magic to ensure Python compatibility.
nlp = pipeline("question-generation")
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
tokenizer = AutoTokenizer.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

content ="""The next day, Agosto spoke with a doctor at the New York City hospital where she works as a medical secretary. He told her that she probably had a pinched nerve and to see a chiropractor. But chiropractic care didn’t help. Months later, Agosto needed a cane to get around, and moving her left leg and arm required lots of concentration. She couldn’t work. Numbness and tingling made cooking and cleaning difficult. It felt a bit like looping a rubber band tightly around a finger until it loses sensation, Agosto says. Once the rubber band comes off, the finger tingles for a bit. But for her, the tingling wouldn’t stop. Finally, she recalls, one chiropractor told her, “I’m not too big of a person to say there’s something very wrong with you, and I don’t know what it is. You need to see a neurologist.” In November 2008, tests confirmed that Agosto had multiple sclerosis. Her immune system was attacking her brain and spinal cord."""
# encode the text into tensor of integers using the tokenize
def summarize(inputs):
    inputs = tokenizer.encode('summarize: ' + inputs, return_tensors='pt', max_length=512, padding='max_length', truncation=True)
    summary_ids = model.generate(inputs,
                                        num_beams=int(3),
                                        no_repeat_ngram_size=2,
                                        length_penalty=1.0,
                                        min_length=100,
                                        max_length= 1000,
                                        early_stopping=False)
    output = tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)
    return output

def QG(inputs):
    return nlp(inputs)